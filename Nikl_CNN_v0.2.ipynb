{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_class_number 749\n",
      "trn_size_per_one_class 649\n",
      "tst_size_per_one_class 100\n",
      "Сlasses dict loaded successfully\n"
     ]
    }
   ],
   "source": [
    "classes = {} #name, amount of material, [indexes of train images], [indexes of test images], [test_data], [test_labels]\n",
    "pickle_classes_file = 'clapeyron_CNN_v0.2_classes.pickle'\n",
    "\n",
    "tst_size_per_one_class = 100\n",
    "trn_size_per_one_class = 0\n",
    "\n",
    "try:\n",
    "    with open(pickle_classes_file, 'rb') as f:\n",
    "        classes = pickle.load(f)\n",
    "    min_class_number = 10000000\n",
    "    for i in range(len(classes)):\n",
    "        len_current_class = classes[i][1]\n",
    "        if (len_current_class < min_class_number):\n",
    "            min_class_number = len_current_class\n",
    "    print('min_class_number',min_class_number)\n",
    "    trn_size_per_one_class = min_class_number - tst_size_per_one_class\n",
    "    print('trn_size_per_one_class',trn_size_per_one_class)\n",
    "    print('tst_size_per_one_class',tst_size_per_one_class)\n",
    "    print('Сlasses dict loaded successfully')\n",
    "except:\n",
    "    print('No saved classes dict, computing classes...')\n",
    "    min_class_number = 10000000\n",
    "    list_classes = os.listdir('./data/data_training')\n",
    "    for i in range(len(list_classes)):\n",
    "        len_current_class = len(os.listdir('./data/data_training'+'/'+list_classes[i]))\n",
    "        classes[i] = [list_classes[i],len_current_class,[],[],[],[]]\n",
    "        if (len_current_class < min_class_number):\n",
    "            min_class_number = len_current_class\n",
    "    print('min_class_number',min_class_number)\n",
    "    trn_size_per_one_class = min_class_number - tst_size_per_one_class\n",
    "    print('trn_size_per_one_class',trn_size_per_one_class)\n",
    "    print('tst_size_per_one_class',tst_size_per_one_class)\n",
    "    for i in range(len(list_classes)):\n",
    "        shuffled_class_indexes = np.random.permutation(len_current_class)\n",
    "        shuffled_class_indexes = np.random.permutation(shuffled_class_indexes) #double shuffling\n",
    "        classes[i][2] = shuffled_class_indexes[:trn_size_per_one_class]\n",
    "        classes[i][3] = shuffled_class_indexes[trn_size_per_one_class:trn_size_per_one_class+100]\n",
    "        pixel_depth = 255.\n",
    "        for j in range(tst_size_per_one_class):\n",
    "            img = imageio.imread('./data/data_training/'+classes[i][0]\n",
    "                             +'/imagenet'+classes[i][0]+str(classes[i][3][j])\n",
    "                             +'.jpg').astype(np.float32)\n",
    "            image_data = (img - pixel_depth / 2) / pixel_depth\n",
    "            classes[i][4].append(image_data)\n",
    "            label = np.zeros(len(classes))\n",
    "            label[i] = 1\n",
    "            classes[i][5].append(label)\n",
    "        classes[i][4] = np.array(classes[i][4])\n",
    "        classes[i][5] = np.array(classes[i][5]) \n",
    "    with open(pickle_classes_file, 'wb') as f:\n",
    "        pickle.dump(classes,f)\n",
    "    print('Сlasses dict saved and computed successfully')\n",
    "\n",
    "N = len(classes) #number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100 #must be %10 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.05)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.zeros(shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Input [224x224x3]\n",
    "    Conv3-16: [224x224x16] weights: (3x3x3)x16\n",
    "        relu\n",
    "    Conv3-16: [224x224x16] weights: (3x3x16)x16\n",
    "        relu\n",
    "    MaxPool2: [112x112x16]\n",
    "    Conv3-32: [112x112x32] weights: (3x3x16)x32\n",
    "        relu\n",
    "    Conv3-32: [112x112x32] weights: (3x3x32)x32\n",
    "        relu\n",
    "    MaxPool2: [56x56x32]\n",
    "    Conv3-64: [56x56x64]   weights: (3x3x32)x64\n",
    "        relu\n",
    "    Conv3-64: [56x56x64]   weights: (3x3x64)x64\n",
    "        relu\n",
    "    MaxPool2: [28x28x64]\n",
    "    Conv3-128:[28x28x128]  weights: (3x3x64)x128\n",
    "        relu\n",
    "    Conv3-128:[28x28x128]  weights: (3x3x128)x128\n",
    "        relu\n",
    "    MaxPool2: [14x14x128]\n",
    "    Conv3-128:[14x14x128]  weights: (3x3x128)x128\n",
    "        relu\n",
    "    Conv3-128:[14x14x128]  weights: (3x3x128)x128\n",
    "        relu\n",
    "    MaxPool2: [7x7x128]\n",
    "        FC:   [1x1x512]\n",
    "        relu\n",
    "        dropout(0.5)\n",
    "        FC:   [1x1x256]\n",
    "        relu\n",
    "        dropout(0.5)\n",
    "        FC:   [1x1x10]\n",
    "        softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    conv_kernel_size = 3\n",
    "    conv_kernel_stride = 1\n",
    "    pool_kernel_size = 2\n",
    "    pool_kernel_stride = 2\n",
    "    \n",
    "    input_size = 224\n",
    "    pool1_size = 112\n",
    "    pool2_size = 56\n",
    "    pool3_size = 28\n",
    "    pool4_size = 14\n",
    "    pool5_size = 7\n",
    "    \n",
    "    input_depth = 3\n",
    "    block1_depth = 16\n",
    "    block2_depth = 32\n",
    "    block3_depth = 64\n",
    "    block4_depth = 128\n",
    "    block5_depth = 128\n",
    "    FC1_depth = 512\n",
    "    dropout1_prob = 0.8\n",
    "    FC2_depth = 256\n",
    "    dropout2_prob = 0.8\n",
    "    FC_output_depth = 10\n",
    "    \n",
    "    conv1_1_weights = weight_variable([conv_kernel_size,conv_kernel_size,input_depth,block1_depth])\n",
    "    conv1_1_biases = bias_variable([block1_depth])\n",
    "    conv1_2_weights = weight_variable([conv_kernel_size,conv_kernel_size,block1_depth,block1_depth])\n",
    "    conv1_2_biases = bias_variable([block1_depth])\n",
    "    \n",
    "    conv2_1_weights = weight_variable([conv_kernel_size,conv_kernel_size,block1_depth,block2_depth])\n",
    "    conv2_1_biases = bias_variable([block2_depth])\n",
    "    conv2_2_weights = weight_variable([conv_kernel_size,conv_kernel_size,block2_depth,block2_depth])\n",
    "    conv2_2_biases = bias_variable([block2_depth])\n",
    "    \n",
    "    conv3_1_weights = weight_variable([conv_kernel_size,conv_kernel_size,block2_depth,block3_depth])\n",
    "    conv3_1_biases = bias_variable([block3_depth])\n",
    "    conv3_2_weights = weight_variable([conv_kernel_size,conv_kernel_size,block3_depth,block3_depth])\n",
    "    conv3_2_biases = bias_variable([block3_depth])\n",
    "    \n",
    "    conv4_1_weights = weight_variable([conv_kernel_size,conv_kernel_size,block3_depth,block4_depth])\n",
    "    conv4_1_biases = bias_variable([block4_depth])\n",
    "    conv4_2_weights = weight_variable([conv_kernel_size,conv_kernel_size,block4_depth,block4_depth])\n",
    "    conv4_2_biases = bias_variable([block4_depth])\n",
    "    \n",
    "    conv5_1_weights = weight_variable([conv_kernel_size,conv_kernel_size,block4_depth,block5_depth])\n",
    "    conv5_1_biases = bias_variable([block5_depth])\n",
    "    conv5_2_weights = weight_variable([conv_kernel_size,conv_kernel_size,block5_depth,block5_depth])\n",
    "    conv5_2_biases = bias_variable([block5_depth])\n",
    "    \n",
    "    FC1_weights = weight_variable([pool5_size,pool5_size,block5_depth,FC1_depth])\n",
    "    FC1_biases = bias_variable([FC1_depth])\n",
    "    FC2_weights = weight_variable([1,1,FC1_depth,FC2_depth])\n",
    "    FC2_biases = bias_variable([FC2_depth])\n",
    "    FC_output_weights = weight_variable([1,1,FC2_depth,FC_output_depth])\n",
    "    FC_output_biases = bias_variable([FC_output_depth])\n",
    "    \n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, input_size, input_size, input_depth))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, FC_output_depth))\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape=(tst_size_per_one_class, input_size, input_size, input_depth))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    def conv_model(data):\n",
    "        conv1_1 = tf.nn.conv2d(data,conv1_1_weights,strides=[1, 1, 1, 1],padding='SAME')\n",
    "        relu1_1 = tf.nn.relu(conv1_1 + conv1_1_biases)\n",
    "\n",
    "        conv1_2 = tf.nn.conv2d(relu1_1,conv1_2_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu1_2 = tf.nn.relu(conv1_2 + conv1_2_biases)\n",
    "\n",
    "        pool1   = tf.nn.max_pool(relu1_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "        conv2_1 = tf.nn.conv2d(pool1,conv2_1_weights,strides=[1, 1, 1, 1],padding='SAME')\n",
    "        relu2_1 = tf.nn.relu(conv2_1 + conv2_1_biases)\n",
    "\n",
    "        conv2_2 = tf.nn.conv2d(relu2_1,conv2_2_weights,strides=[1,1,1,1], padding='SAME')\n",
    "        relu2_2 = tf.nn.relu(conv2_2 + conv2_2_biases)\n",
    "\n",
    "        pool2   = tf.nn.max_pool(relu2_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "        conv3_1 = tf.nn.conv2d(pool2,conv3_1_weights,strides=[1, 1, 1, 1],padding='SAME')\n",
    "        relu3_1 = tf.nn.relu(conv3_1 + conv3_1_biases)\n",
    "\n",
    "        conv3_2 = tf.nn.conv2d(relu3_1,conv3_2_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu3_2 = tf.nn.relu(conv3_2 + conv3_2_biases)\n",
    "\n",
    "        pool3   = tf.nn.max_pool(relu3_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "        conv4_1 = tf.nn.conv2d(pool3,conv4_1_weights,strides=[1, 1, 1, 1],padding='SAME')\n",
    "        relu4_1 = tf.nn.relu(conv4_1 + conv4_1_biases)\n",
    "\n",
    "        conv4_2 = tf.nn.conv2d(relu4_1,conv4_2_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu4_2 = tf.nn.relu(conv4_2 + conv4_2_biases)\n",
    "\n",
    "        pool4   = tf.nn.max_pool(relu4_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "        conv5_1 = tf.nn.conv2d(pool4,conv5_1_weights,strides=[1, 1, 1, 1],padding='SAME')\n",
    "        relu5_1 = tf.nn.relu(conv5_1 + conv5_1_biases)\n",
    "\n",
    "        conv5_2 = tf.nn.conv2d(relu5_1,conv5_2_weights,strides=[1,1,1,1],padding='SAME')\n",
    "        relu5_2 = tf.nn.relu(conv5_2 + conv5_2_biases)\n",
    "\n",
    "        pool5   = tf.nn.max_pool(relu5_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "        return pool5\n",
    "    \n",
    "    def FC_model_train(pool5):\n",
    "        FC1     = tf.nn.conv2d(pool5,FC1_weights,strides=[1,1,1,1],padding='VALID')\n",
    "        reluFC1 = tf.nn.relu(FC1 + FC1_biases)\n",
    "        dropout1 = tf.nn.dropout(reluFC1,dropout1_prob)\n",
    "\n",
    "        FC2     = tf.nn.conv2d(dropout1,FC2_weights,strides=[1,1,1,1],padding='VALID')\n",
    "        reluFC2 = tf.nn.relu(FC2 + FC2_biases)\n",
    "        dropout2 = tf.nn.dropout(reluFC2,dropout2_prob)\n",
    "\n",
    "        FC_output = tf.nn.conv2d(dropout2,FC_output_weights,strides=[1,1,1,1],padding='VALID') + FC_output_biases\n",
    "        return tf.reshape(FC_output,[int(pool5.shape[0]),10])\n",
    "    \n",
    "    def FC_model_predict(pool5):\n",
    "        FC1     = tf.nn.conv2d(pool5,FC1_weights,strides=[1,1,1,1],padding='VALID')\n",
    "        reluFC1 = tf.nn.relu(FC1 + FC1_biases)\n",
    "\n",
    "        FC2     = tf.nn.conv2d(reluFC1,FC2_weights,strides=[1,1,1,1],padding='VALID')\n",
    "        reluFC2 = tf.nn.relu(FC2 + FC2_biases)\n",
    "\n",
    "        FC_output = tf.nn.conv2d(reluFC2,FC_output_weights,strides=[1,1,1,1],padding='VALID') + FC_output_biases\n",
    "        return tf.reshape(FC_output,[int(pool5.shape[0]),10])\n",
    "    \n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, input_size, input_size, input_depth))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, FC_output_depth))\n",
    "    train_logits = FC_model_train(conv_model(tf_train_dataset))\n",
    "    train_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels,logits=train_logits))\n",
    "    learning_rate = 0.1\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(train_loss)\n",
    "    train_prediction = tf.nn.softmax(train_logits)\n",
    "    \n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape=(tst_size_per_one_class, input_size, input_size, input_depth))\n",
    "    tf_test_labels = tf.placeholder(tf.float32, shape=(tst_size_per_one_class, FC_output_depth))\n",
    "    test_logits = FC_model_predict(conv_model(tf_test_dataset))\n",
    "    test_prediction  = tf.nn.softmax(test_logits)\n",
    "    test_losses = tf.nn.softmax_cross_entropy_with_logits(labels=tf_test_labels,logits=test_logits)\n",
    "    test_loss = tf.reduce_mean(test_losses)\n",
    "    \n",
    "    tf_one_image = tf.placeholder(tf.float32, shape=(1, input_size, input_size, input_depth))\n",
    "    tf_one_label = tf.placeholder(tf.float32, shape=(1, FC_output_depth))\n",
    "    one_prediction = tf.nn.softmax(FC_model_predict(conv_model(tf_one_image)))\n",
    "    one_loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf_one_label,logits=one_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_depth = 255.0\n",
    "if(batch_size%N != 0):\n",
    "    print('WARNING:',batch_size,'%',N,'!=',0)\n",
    "def generate_batch():\n",
    "    batch_data = []\n",
    "    batch_labels = []\n",
    "    for i in range(N):\n",
    "        class_batch_size = int(batch_size/N)\n",
    "        class_batch_indexes = np.random.permutation(trn_size_per_one_class)[:class_batch_size]\n",
    "        for j in range(class_batch_size):\n",
    "            img = imageio.imread('./data/data_training/'+classes[i][0]\n",
    "                             +'/imagenet'+classes[i][0]+str(classes[i][2][class_batch_indexes[j]])\n",
    "                             +'.jpg').astype(np.float32)\n",
    "            image_data = (img - pixel_depth / 2) / pixel_depth\n",
    "            batch_data.append(np.array(image_data))\n",
    "            label = np.zeros(N)\n",
    "            label[i] = 1\n",
    "            batch_labels.append(label)\n",
    "    return np.array(batch_data),np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) \n",
    "            / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss at step 0: 2.302588\n",
      "Batch accuracy: 8.0%\n",
      "Test accuracy: 9.7%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter0.ckpt\n",
      "Batch loss at step 100: 2.304182\n",
      "Batch accuracy: 8.0%\n",
      "Batch loss at step 200: 2.300875\n",
      "Batch accuracy: 13.0%\n",
      "Batch loss at step 300: 2.302205\n",
      "Batch accuracy: 13.0%\n",
      "Batch loss at step 400: 2.277093\n",
      "Batch accuracy: 18.0%\n",
      "Batch loss at step 500: 2.191569\n",
      "Batch accuracy: 24.0%\n",
      "Batch loss at step 600: 2.247184\n",
      "Batch accuracy: 14.0%\n",
      "Batch loss at step 700: 2.134764\n",
      "Batch accuracy: 24.0%\n",
      "Batch loss at step 800: 1.897633\n",
      "Batch accuracy: 36.0%\n",
      "Batch loss at step 900: 1.872838\n",
      "Batch accuracy: 40.0%\n",
      "Batch loss at step 1000: 1.901065\n",
      "Batch accuracy: 32.0%\n",
      "Test accuracy: 28.5%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter1000.ckpt\n",
      "Batch loss at step 1100: 1.664441\n",
      "Batch accuracy: 47.0%\n",
      "Batch loss at step 1200: 1.707003\n",
      "Batch accuracy: 45.0%\n",
      "Batch loss at step 1300: 1.586417\n",
      "Batch accuracy: 52.0%\n",
      "Batch loss at step 1400: 1.322074\n",
      "Batch accuracy: 56.0%\n",
      "Batch loss at step 1500: 1.340862\n",
      "Batch accuracy: 56.0%\n",
      "Batch loss at step 1600: 0.615119\n",
      "Batch accuracy: 84.0%\n",
      "Batch loss at step 1700: 0.834088\n",
      "Batch accuracy: 74.0%\n",
      "Batch loss at step 1800: 0.638153\n",
      "Batch accuracy: 78.0%\n",
      "Batch loss at step 1900: 0.977308\n",
      "Batch accuracy: 63.0%\n",
      "Batch loss at step 2000: 0.402212\n",
      "Batch accuracy: 84.0%\n",
      "Test accuracy: 32.8%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter2000.ckpt\n",
      "Batch loss at step 2100: 0.458001\n",
      "Batch accuracy: 88.0%\n",
      "Batch loss at step 2200: 0.427929\n",
      "Batch accuracy: 87.0%\n",
      "Batch loss at step 2300: 0.345215\n",
      "Batch accuracy: 93.0%\n",
      "Batch loss at step 2400: 0.260682\n",
      "Batch accuracy: 92.0%\n",
      "Batch loss at step 2500: 0.163395\n",
      "Batch accuracy: 93.0%\n",
      "Batch loss at step 2600: 0.140696\n",
      "Batch accuracy: 96.0%\n",
      "Batch loss at step 2700: 0.238493\n",
      "Batch accuracy: 93.0%\n",
      "Batch loss at step 2800: 0.061774\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 2900: 0.135343\n",
      "Batch accuracy: 96.0%\n",
      "Batch loss at step 3000: 0.064119\n",
      "Batch accuracy: 99.0%\n",
      "Test accuracy: 32.6%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter3000.ckpt\n",
      "Batch loss at step 3100: 0.048078\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 3200: 0.108935\n",
      "Batch accuracy: 95.0%\n",
      "Batch loss at step 3300: 0.100353\n",
      "Batch accuracy: 96.0%\n",
      "Batch loss at step 3400: 0.010051\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 3500: 0.035290\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 3600: 0.070702\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 3700: 0.049215\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 3800: 0.061828\n",
      "Batch accuracy: 97.0%\n",
      "Batch loss at step 3900: 0.045676\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 4000: 0.105785\n",
      "Batch accuracy: 98.0%\n",
      "Test accuracy: 33.0%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter4000.ckpt\n",
      "Batch loss at step 4100: 0.119779\n",
      "Batch accuracy: 96.0%\n",
      "Batch loss at step 4200: 0.041008\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 4300: 0.008137\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 4400: 0.118049\n",
      "Batch accuracy: 95.0%\n",
      "Batch loss at step 4500: 0.007102\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 4600: 0.005514\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 4700: 0.035537\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 4800: 0.070236\n",
      "Batch accuracy: 97.0%\n",
      "Batch loss at step 4900: 0.016541\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 5000: 0.037555\n",
      "Batch accuracy: 98.0%\n",
      "Test accuracy: 32.1%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter5000.ckpt\n",
      "Batch loss at step 5100: 0.013447\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 5200: 0.062009\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 5300: 0.069945\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 5400: 0.006506\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 5500: 0.042077\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 5600: 0.020507\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 5700: 0.011670\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 5800: 0.021614\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 5900: 0.011030\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 6000: 0.002961\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 32.2%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter6000.ckpt\n",
      "Batch loss at step 6100: 0.052148\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 6200: 0.020689\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 6300: 0.003107\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 6400: 0.048531\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 6500: 0.008990\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 6600: 0.001478\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 6700: 0.027459\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 6800: 0.009918\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 6900: 0.005641\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 7000: 0.056070\n",
      "Batch accuracy: 99.0%\n",
      "Test accuracy: 34.2%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter7000.ckpt\n",
      "Batch loss at step 7100: 0.041097\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 7200: 0.012009\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 7300: 0.003556\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 7400: 0.018719\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 7500: 0.000346\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 7600: 0.013278\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 7700: 0.035887\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 7800: 0.004432\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 7900: 0.007001\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 8000: 0.004745\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 32.6%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "Batch loss at step 8100: 0.033583\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 8200: 0.001951\n",
      "Batch accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "#LAST\n",
    "num_steps = 10001\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for step in range(num_steps):\n",
    "        batch_data,batch_labels = generate_batch()\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            print('Batch loss at step %d: %f' % (step, l))\n",
    "            print('Batch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "        if (step % 1000 == 0):\n",
    "            accuracy_full = 0.\n",
    "            for i in range(N):\n",
    "                test_data,test_labels = classes[i][4],classes[i][5]\n",
    "                acc = accuracy(test_prediction.eval(feed_dict={tf_test_dataset:test_data}), test_labels)\n",
    "                accuracy_full += acc\n",
    "            accuracy_full = accuracy_full/N\n",
    "            print('Test accuracy: %.1f%%' % accuracy_full)\n",
    "            save_path = saver.save(session, \"./modelTmp/model_v0.2_iter\"+str(step)+\".ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "Batch loss at step 8000: 0.000431\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 32.8%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "Batch loss at step 8100: 0.014550\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 8200: 0.005221\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 8300: 0.002155\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 8400: 0.033818\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 8500: 0.030945\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 8600: 0.043643\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 8700: 0.007116\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 8800: 0.010784\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 8900: 0.025607\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 9000: 0.000379\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 33.4%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter9000.ckpt\n",
      "Batch loss at step 9100: 0.000477\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 9200: 0.003736\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 9300: 0.000068\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 9400: 0.005237\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 9500: 0.005036\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 9600: 0.039974\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 9700: 0.000989\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 9800: 0.076095\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 9900: 0.004000\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 10000: 0.000346\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 33.7%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter10000.ckpt\n",
      "Batch loss at step 10100: 0.020372\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 10200: 0.000500\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 10300: 0.050195\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 10400: 0.008720\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 10500: 0.007464\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 10600: 0.007351\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 10700: 0.000309\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 10800: 0.001265\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 10900: 0.003032\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 11000: 0.000905\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 33.4%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter11000.ckpt\n",
      "Batch loss at step 11100: 0.032986\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 11200: 0.027018\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 11300: 0.047732\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 11400: 0.009897\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 11500: 0.007232\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 11600: 0.009751\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 11700: 0.001586\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 11800: 0.004809\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 11900: 0.001016\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 12000: 0.002850\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 33.1%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter12000.ckpt\n",
      "Batch loss at step 12100: 0.001434\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 12200: 0.001837\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 12300: 0.007110\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 12400: 0.000169\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 12500: 0.000541\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 12600: 0.001765\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 12700: 0.000814\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 12800: 0.000036\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 12900: 0.004749\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 13000: 0.000124\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 32.8%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter13000.ckpt\n",
      "Batch loss at step 13100: 0.027471\n",
      "Batch accuracy: 98.0%\n",
      "Batch loss at step 13200: 0.003630\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 13300: 0.005334\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 13400: 0.001832\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 13500: 0.013077\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 13600: 0.003046\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 13700: 0.000139\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 13800: 0.003488\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 13900: 0.001407\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 14000: 0.005118\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 34.5%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "Batch loss at step 14100: 0.015712\n",
      "Batch accuracy: 99.0%\n",
      "Batch loss at step 14200: 0.000234\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 14300: 0.003334\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 14400: 0.000674\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 14500: 0.001031\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 14600: 0.000742\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 14700: 0.000093\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 14800: 0.000543\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 14900: 0.000154\n",
      "Batch accuracy: 100.0%\n",
      "Batch loss at step 15000: 0.001535\n",
      "Batch accuracy: 100.0%\n",
      "Test accuracy: 33.7%\n",
      "Model saved in file: ./modelTmp/model_v0.2_iter15000.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 15001\n",
    "learning_rate = 0.001\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver.restore(session,'./modelTmp/model_v0.2_iter8000.ckpt')\n",
    "    for step in range(num_steps)[8000:]:\n",
    "        batch_data,batch_labels = generate_batch()\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, train_loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            print('Batch loss at step %d: %f' % (step, l))\n",
    "            print('Batch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "        if (step % 1000 == 0):\n",
    "            accuracy_full = 0.\n",
    "            for i in range(N):\n",
    "                test_data,test_labels = classes[i][4],classes[i][5]\n",
    "                acc = accuracy(test_prediction.eval(feed_dict={tf_test_dataset:test_data}), test_labels)\n",
    "                accuracy_full += acc\n",
    "            accuracy_full = accuracy_full/N\n",
    "            print('Test accuracy: %.1f%%' % accuracy_full)\n",
    "            save_path = saver.save(session, \"./modelTmp/model_v0.2_iter\"+str(step)+\".ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctness checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_loss = []\n",
    "all_without_train_acc_loss = []\n",
    "train_acc_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "Model restored\n",
      "Batch loss at step: 0.044340\n",
      "Batch accuracy: 98.0%\n",
      "bottle 30.0 6.8\n",
      "headphones 39.0 5.0\n",
      "human 25.0 6.9\n",
      "key 25.0 7.0\n",
      "laptop 32.0 7.0\n",
      "pen 45.0 5.5\n",
      "phone 20.0 9.1\n",
      "shoes 35.0 6.3\n",
      "sodacan 34.0 5.7\n",
      "wallet 41.0 5.6\n",
      "Full test accuracy: 32.6%\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 # not all GPU memory (1.0)\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver.restore(session,'./modelTmp/model_v0.2_iter8000.ckpt')\n",
    "    print('Model restored')\n",
    "    batch_data,batch_labels = generate_batch()\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    l, predictions = session.run([train_loss, train_prediction], feed_dict=feed_dict)\n",
    "    print('Batch loss at step: %f' % (l))\n",
    "    print('Batch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "    accuracy_full = 0.\n",
    "    for i in range(N):\n",
    "        test_data,test_labels = classes[i][4],classes[i][5]\n",
    "        feed_dict={tf_test_dataset:test_data,tf_test_labels:test_labels}\n",
    "        l, predictions = session.run([test_loss, test_prediction], feed_dict=feed_dict)\n",
    "        acc = accuracy(predictions, test_labels)\n",
    "        print(classes[i][0],acc,'%.1f'%l)\n",
    "        test_acc_loss.append([classes[i][1],acc,l])\n",
    "        accuracy_full += acc\n",
    "    accuracy_full = accuracy_full/N\n",
    "    print('Full test accuracy: %.1f%%' % accuracy_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_loss_for_class_without_train(class_number):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        saver.restore(session,'./modelTmp/model_v0.2_iter8000.ckpt')\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        losses = []\n",
    "        label = np.zeros(N)\n",
    "        label[class_number] = 1\n",
    "        name = classes[class_number][0]\n",
    "        for i in range(len(os.listdir('./data/data_training/'+name))):\n",
    "            if (i not in classes[class_number][2]):\n",
    "                img = imageio.imread('./data/data_training/'+name\n",
    "                                     +'/imagenet'+name+str(i)\n",
    "                                     +'.jpg').astype(np.float32)\n",
    "                image_data = (img - pixel_depth / 2) / pixel_depth\n",
    "                feed_dict={tf_one_image : [image_data],tf_one_label : [label]}\n",
    "                prediction = session.run(one_prediction, feed_dict=feed_dict)\n",
    "                predictions.append(prediction[0])\n",
    "                labels.append(label)\n",
    "                losses.append(-np.log(prediction[0][class_number]))\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "        losses = np.array(losses)\n",
    "        acc = accuracy(predictions,labels)\n",
    "        l = losses.mean()\n",
    "    return acc,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "bottle 18.3918669131 8.27846\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "headphones 47.6851851852 4.41025\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "human 20.9376664891 7.55959\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "key 29.6167247387 6.81258\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "laptop 25.7575757576 8.64961\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "pen 26.8848626534 8.20556\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "phone 23.3009708738 8.19384\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "shoes 18.5313075506 9.98322\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "sodacan 42.1203438395 5.31712\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "wallet 41.0 5.63644\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    acc,l = accuracy_loss_for_class_without_train(i)\n",
    "    print(classes[i][0],acc,l)\n",
    "    all_without_train_acc_loss.append([classes[i][1],acc,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_loss_for_class_train(class_number):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        saver.restore(session,'./modelTmp/model_v0.2_iter8000.ckpt')\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        losses = []\n",
    "        label = np.zeros(N)\n",
    "        label[class_number] = 1\n",
    "        name = classes[class_number][0]\n",
    "        for i in range(classes[class_number][2].shape[0]):\n",
    "            img = imageio.imread('./data/data_training/'+name\n",
    "                                    +'/imagenet'+name+str(classes[class_number][2][i])\n",
    "                                    +'.jpg').astype(np.float32)\n",
    "            image_data = (img - pixel_depth / 2) / pixel_depth\n",
    "            feed_dict={tf_one_image : [image_data],tf_one_label : [label]}\n",
    "            prediction = session.run(one_prediction, feed_dict=feed_dict)\n",
    "            predictions.append(prediction[0])\n",
    "            labels.append(label)\n",
    "            losses.append(-np.log(prediction[0][class_number]))\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "        losses = np.array(losses)\n",
    "        acc = accuracy(predictions,labels)\n",
    "        l = losses.mean()\n",
    "    return acc,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "bottle 99.2295839753 0.0154817\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "headphones 100.0 0.00056449\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "human 100.0 0.000125679\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "key 99.6918335901 0.00770311\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "laptop 100.0 0.00021163\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "pen 100.0 0.00105732\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "phone 100.0 7.74517e-06\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "shoes 100.0 6.2954e-05\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "sodacan 99.8459167951 0.00371225\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "wallet 100.0 0.000356995\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    acc,l = accuracy_loss_for_class_train(i)\n",
    "    print(classes[i][0],acc,l)\n",
    "    train_acc_loss.append([classes[i][1],acc,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1731, 99.229583975346685, 0.015481679],\n",
       " [865, 100.0, 0.00056449044],\n",
       " [2526, 100.0, 0.0001256791],\n",
       " [936, 99.691833590138671, 0.0077031082],\n",
       " [1771, 100.0, 0.00021162983],\n",
       " [2360, 100.0, 0.0010573247],\n",
       " [1473, 100.0, 7.7451723e-06],\n",
       " [9337, 100.0, 6.2954045e-05],\n",
       " [998, 99.845916795069343, 0.0037122499],\n",
       " [749, 100.0, 0.00035699501]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_data):\n",
    "    prediction = np.zeros(N)\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.9 # not all GPU memory (1.0)\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        saver.restore(session,'./modelTmp/model_v0.2.ckpt')\n",
    "        print('Model restored')\n",
    "        prediction = one_prediction.eval(feed_dict={tf_one_image : image_data})\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_loss = np.array(test_acc_loss)\n",
    "all_without_train_acc_loss = np.array(all_without_train_acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ecf02400f0>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eceaa55e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(17, 9))\n",
    "plt.axis([0,10000,0,100])\n",
    "plt.xticks(np.arange(min(all_without_train_acc_loss[:,0]), max(all_without_train_acc_loss[:,0])+1, 300.0))\n",
    "plt.grid(True)\n",
    "plt.plot(all_without_train_acc_loss[:,0],all_without_train_acc_loss[:,1],'ro')\n",
    "plt.plot(test_acc_loss[:,0],test_acc_loss[:,1],'ro',color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eceaa9dc18>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eceab24518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(17, 9))\n",
    "plt.axis([0,10000,0,12])\n",
    "plt.xticks(np.arange(min(all_without_train_acc_loss[:,0]), max(all_without_train_acc_loss[:,0])+1, 300.0))\n",
    "plt.grid(True)\n",
    "plt.plot(all_without_train_acc_loss[:,0],all_without_train_acc_loss[:,2],'ro')\n",
    "plt.plot(test_acc_loss[:,0],test_acc_loss[:,2],'ro',color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iter7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter7000.ckpt\n",
      "Model restored\n",
      "Batch loss at step: 0.014245\n",
      "Batch accuracy: 99.0%\n",
      "bottle 34.0 4.1\n",
      "headphones 38.0 3.6\n",
      "human 23.0 4.9\n",
      "key 27.0 5.1\n",
      "laptop 36.0 5.1\n",
      "pen 44.0 4.5\n",
      "phone 20.0 6.5\n",
      "shoes 41.0 4.3\n",
      "sodacan 31.0 4.0\n",
      "wallet 48.0 3.6\n",
      "Full test accuracy: 34.2%\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 # not all GPU memory (1.0)\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver.restore(session,'./modelTmp/model_v0.2_iter7000.ckpt')\n",
    "    print('Model restored')\n",
    "    batch_data,batch_labels = generate_batch()\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    l, predictions = session.run([train_loss, train_prediction], feed_dict=feed_dict)\n",
    "    print('Batch loss at step: %f' % (l))\n",
    "    print('Batch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "    accuracy_full = 0.\n",
    "    for i in range(N):\n",
    "        test_data,test_labels = classes[i][4],classes[i][5]\n",
    "        feed_dict={tf_test_dataset:test_data,tf_test_labels:test_labels}\n",
    "        l, predictions = session.run([test_loss, test_prediction], feed_dict=feed_dict)\n",
    "        acc = accuracy(predictions, test_labels)\n",
    "        print(classes[i][0],acc,'%.1f'%l)\n",
    "        test_acc_loss.append([classes[i][1],acc,l])\n",
    "        accuracy_full += acc\n",
    "    accuracy_full = accuracy_full/N\n",
    "    print('Full test accuracy: %.1f%%' % accuracy_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_loss_for_class_without_train(class_number):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        saver.restore(session,'./modelTmp/model_v0.2_iter8000.ckpt')\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        losses = []\n",
    "        label = np.zeros(N)\n",
    "        label[class_number] = 1\n",
    "        name = classes[class_number][0]\n",
    "        for i in range(len(os.listdir('./data/data_training/'+name))):\n",
    "            if (i not in classes[class_number][2]):\n",
    "                img = imageio.imread('./data/data_training/'+name\n",
    "                                     +'/imagenet'+name+str(i)\n",
    "                                     +'.jpg').astype(np.float32)\n",
    "                image_data = (img - pixel_depth / 2) / pixel_depth\n",
    "                feed_dict={tf_one_image : [image_data],tf_one_label : [label]}\n",
    "                prediction = session.run(one_prediction, feed_dict=feed_dict)\n",
    "                predictions.append(prediction[0])\n",
    "                labels.append(label)\n",
    "                losses.append(-np.log(prediction[0][class_number]))\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "        losses = np.array(losses)\n",
    "        acc = accuracy(predictions,labels)\n",
    "        l = losses.mean()\n",
    "    return acc,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "bottle 18.3918669131 8.27846\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "headphones 47.6851851852 4.41025\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "human 20.9376664891 7.55959\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "key 29.6167247387 6.81258\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "laptop 25.7575757576 8.64961\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "pen 26.8848626534 8.20556\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "phone 23.3009708738 8.19384\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "shoes 18.5313075506 9.98322\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "sodacan 42.1203438395 5.31712\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter8000.ckpt\n",
      "wallet 41.0 5.63644\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    acc,l = accuracy_loss_for_class_without_train(i)\n",
    "    print(classes[i][0],acc,l)\n",
    "    all_without_train_acc_loss.append([classes[i][1],acc,l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iter 14000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "Model restored\n",
      "Batch loss at step: 0.067281\n",
      "Batch accuracy: 99.0%\n",
      "bottle 34.0 5.4\n",
      "headphones 37.0 5.2\n",
      "human 19.0 6.4\n",
      "key 28.0 6.5\n",
      "laptop 40.0 5.2\n",
      "pen 46.0 4.9\n",
      "phone 19.0 7.9\n",
      "shoes 47.0 4.1\n",
      "sodacan 33.0 5.4\n",
      "wallet 42.0 5.4\n",
      "Full test accuracy: 34.5%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    saver.restore(session,'./modelTmp/model_v0.2_iter14000.ckpt')\n",
    "    print('Model restored')\n",
    "    batch_data,batch_labels = generate_batch()\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    l, predictions = session.run([train_loss, train_prediction], feed_dict=feed_dict)\n",
    "    print('Batch loss at step: %f' % (l))\n",
    "    print('Batch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "    accuracy_full = 0.\n",
    "    for i in range(N):\n",
    "        test_data,test_labels = classes[i][4],classes[i][5]\n",
    "        feed_dict={tf_test_dataset:test_data,tf_test_labels:test_labels}\n",
    "        l, predictions = session.run([test_loss, test_prediction], feed_dict=feed_dict)\n",
    "        acc = accuracy(predictions, test_labels)\n",
    "        print(classes[i][0],acc,'%.1f'%l)\n",
    "        test_acc_loss.append([classes[i][1],acc,l])\n",
    "        accuracy_full += acc\n",
    "    accuracy_full = accuracy_full/N\n",
    "    print('Full test accuracy: %.1f%%' % accuracy_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1731, 34.0, 5.4307065],\n",
       " [865, 37.0, 5.2480931],\n",
       " [2526, 19.0, 6.4139013],\n",
       " [936, 28.0, 6.4831662],\n",
       " [1771, 40.0, 5.2175813],\n",
       " [2360, 46.0, 4.9227891],\n",
       " [1473, 19.0, 7.9091959],\n",
       " [9337, 47.0, 4.066606],\n",
       " [998, 33.0, 5.3956523],\n",
       " [749, 42.0, 5.418314]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1731, 21.441774491682072, 6.6577969],\n",
       " [865, 42.129629629629626, 5.1347985],\n",
       " [2526, 22.322855620671284, 6.6143427],\n",
       " [936, 26.132404181184668, 6.7748246],\n",
       " [1771, 31.016042780748663, 6.6512437],\n",
       " [2360, 24.430157802454705, 7.5511203],\n",
       " [1473, 23.058252427184467, 7.492557],\n",
       " [9337, 25.161141804788215, 7.0903354],\n",
       " [998, 35.816618911174785, 5.2326388],\n",
       " [749, 42.0, 5.418314]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_without_train_acc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1731, 99.229583975346685, 0.008127789],\n",
       " [865, 100.0, 0.001192083],\n",
       " [2526, 100.0, 1.7883553e-05],\n",
       " [936, 99.691833590138671, 0.0056010108],\n",
       " [1771, 100.0, 7.5789553e-06],\n",
       " [2360, 100.0, 4.2368989e-05],\n",
       " [1473, 100.0, 8.5280435e-06],\n",
       " [9337, 100.0, 2.529331e-05],\n",
       " [998, 99.845916795069343, 0.0059177643],\n",
       " [749, 99.845916795069343, 0.0013709463]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025850929940455"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_loss_for_class_without_train(class_number):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        saver.restore(session,'./modelTmp/model_v0.2_iter14000.ckpt')\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        losses = []\n",
    "        label = np.zeros(N)\n",
    "        label[class_number] = 1\n",
    "        name = classes[class_number][0]\n",
    "        for i in range(len(os.listdir('./data/data_training/'+name))):\n",
    "            if (i not in classes[class_number][2]):\n",
    "                img = imageio.imread('./data/data_training/'+name\n",
    "                                     +'/imagenet'+name+str(i)\n",
    "                                     +'.jpg').astype(np.float32)\n",
    "                image_data = (img - pixel_depth / 2) / pixel_depth\n",
    "                feed_dict={tf_one_image : [image_data],tf_one_label : [label]}\n",
    "                prediction = session.run(one_prediction, feed_dict=feed_dict)\n",
    "                predictions.append(prediction[0])\n",
    "                labels.append(label)\n",
    "                losses.append(-np.log(prediction[0][class_number]))\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "        losses = np.array(losses)\n",
    "        acc = accuracy(predictions,labels)\n",
    "        l = losses.mean()\n",
    "    return acc,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "bottle 21.4417744917 6.6578\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "headphones 42.1296296296 5.1348\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "human 22.3228556207 6.61434\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "key 26.1324041812 6.77482\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "laptop 31.0160427807 6.65124\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "pen 24.4301578025 7.55112\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "phone 23.0582524272 7.49256\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "shoes 25.1611418048 7.09034\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "sodacan 35.8166189112 5.23264\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "wallet 42.0 5.41831\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    acc,l = accuracy_loss_for_class_without_train(i)\n",
    "    print(classes[i][0],acc,l)\n",
    "    all_without_train_acc_loss.append([classes[i][1],acc,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_loss_for_class_train(class_number):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        saver.restore(session,'./modelTmp/model_v0.2_iter14000.ckpt')\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        losses = []\n",
    "        label = np.zeros(N)\n",
    "        label[class_number] = 1\n",
    "        name = classes[class_number][0]\n",
    "        for i in range(classes[class_number][2].shape[0]):\n",
    "            img = imageio.imread('./data/data_training/'+name\n",
    "                                    +'/imagenet'+name+str(classes[class_number][2][i])\n",
    "                                    +'.jpg').astype(np.float32)\n",
    "            image_data = (img - pixel_depth / 2) / pixel_depth\n",
    "            feed_dict={tf_one_image : [image_data],tf_one_label : [label]}\n",
    "            prediction = session.run(one_prediction, feed_dict=feed_dict)\n",
    "            predictions.append(prediction[0])\n",
    "            labels.append(label)\n",
    "            losses.append(-np.log(prediction[0][class_number]))\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "        losses = np.array(losses)\n",
    "        acc = accuracy(predictions,labels)\n",
    "        l = losses.mean()\n",
    "    return acc,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "bottle 99.2295839753 0.00812779\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "headphones 100.0 0.00119208\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "human 100.0 1.78836e-05\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "key 99.6918335901 0.00560101\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "laptop 100.0 7.57896e-06\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "pen 100.0 4.2369e-05\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "phone 100.0 8.52804e-06\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "shoes 100.0 2.52933e-05\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "sodacan 99.8459167951 0.00591776\n",
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "wallet 99.8459167951 0.00137095\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    acc,l = accuracy_loss_for_class_train(i)\n",
    "    print(classes[i][0],acc,l)\n",
    "    train_acc_loss.append([classes[i][1],acc,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(conf_file):\n",
    "    results_acc = [[],[],[],[],[],[]]\n",
    "    results_loss = [[],[],[],[],[],[]]\n",
    "    \n",
    "    test_acc_loss = []\n",
    "    all_without_train_acc_loss = []\n",
    "    train_acc_loss = []\n",
    "    \n",
    "    def accuracy_loss_for_class_train(class_number):\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        losses = []\n",
    "        label = np.zeros(N)\n",
    "        label[class_number] = 1\n",
    "        name = classes[class_number][0]\n",
    "        for i in range(classes[class_number][2].shape[0]):\n",
    "            img = imageio.imread('./data/data_training/'+name\n",
    "                                    +'/imagenet'+name+str(classes[class_number][2][i])\n",
    "                                    +'.jpg').astype(np.float32)\n",
    "            image_data = (img - pixel_depth / 2) / pixel_depth\n",
    "            feed_dict={tf_one_image : [image_data],tf_one_label : [label]}\n",
    "            prediction = session.run(one_prediction, feed_dict=feed_dict)\n",
    "            predictions.append(prediction[0])\n",
    "            labels.append(label)\n",
    "            losses.append(-np.log(prediction[0][class_number]))\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "        losses = np.array(losses)\n",
    "        acc = accuracy(predictions,labels)\n",
    "        l = losses.mean()\n",
    "        return acc,l\n",
    "\n",
    "    def accuracy_loss_for_class_without_train(class_number):\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        losses = []\n",
    "        label = np.zeros(N)\n",
    "        label[class_number] = 1\n",
    "        name = classes[class_number][0]\n",
    "        for i in range(len(os.listdir('./data/data_training/'+name))):\n",
    "            if (i not in classes[class_number][2]):\n",
    "                img = imageio.imread('./data/data_training/'+name\n",
    "                                     +'/imagenet'+name+str(i)\n",
    "                                     +'.jpg').astype(np.float32)\n",
    "                image_data = (img - pixel_depth / 2) / pixel_depth\n",
    "                feed_dict={tf_one_image : [image_data],tf_one_label : [label]}\n",
    "                prediction = session.run(one_prediction, feed_dict=feed_dict)\n",
    "                predictions.append(prediction[0])\n",
    "                labels.append(label)\n",
    "                losses.append(-np.log(prediction[0][class_number]))\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "        losses = np.array(losses)\n",
    "        acc = accuracy(predictions,labels)\n",
    "        l = losses.mean()\n",
    "        return acc,l\n",
    "    \n",
    "    with tf.Session(graph=graph) as session:\n",
    "        saver.restore(session,conf_file)\n",
    "        \n",
    "        for i in range(N):\n",
    "            acc,l = accuracy_loss_for_class_train(i)\n",
    "            train_acc_loss.append([classes[i][1],acc,l])\n",
    "        train_acc_loss = np.array(train_acc_loss)\n",
    "        \n",
    "        for i in range(N):\n",
    "            test_data,test_labels = classes[i][4],classes[i][5]\n",
    "            feed_dict={tf_test_dataset:test_data,tf_test_labels:test_labels}\n",
    "            l, predictions = session.run([test_loss, test_prediction], feed_dict=feed_dict)\n",
    "            acc = accuracy(predictions, test_labels)\n",
    "            test_acc_loss.append([classes[i][1],acc,l])\n",
    "        test_acc_loss = np.array(test_acc_loss)\n",
    "        test_acc_loss_mean = (test_acc_loss[:,1].mean(),test_acc_loss[:,2].mean())\n",
    "        print('test_acc_loss_mean',test_acc_loss_mean)\n",
    "    \n",
    "        for i in range(N):\n",
    "            acc,l = accuracy_loss_for_class_without_train(i)\n",
    "            all_without_train_acc_loss.append([classes[i][1],acc,l])\n",
    "        all_without_train_acc_loss = np.array(all_without_train_acc_loss)\n",
    "    \n",
    "    def s(st):\n",
    "        return st[1]\n",
    "    classessorted = []\n",
    "    for i in range(N):\n",
    "        classessorted.append([i,classes[i][1]])\n",
    "    classessorted.sort(key=s)\n",
    "    classessorted = np.array(classessorted)\n",
    "    \n",
    "    for i in range(N):\n",
    "        j = classessorted[i][0]\n",
    "        results_acc[0].append(j)\n",
    "        results_acc[1].append(train_acc_loss[j][0])\n",
    "        results_acc[2].append(train_acc_loss[j][1])\n",
    "        results_acc[3].append(test_acc_loss[j][1])\n",
    "        results_acc[4].append(all_without_train_acc_loss[j][1])\n",
    "        results_acc[5].append(np.abs(all_without_train_acc_loss[j][1]-test_acc_loss[j][1]))\n",
    "        \n",
    "        results_loss[0].append(j)\n",
    "        results_loss[1].append(train_acc_loss[j][0])\n",
    "        results_loss[2].append(train_acc_loss[j][2])\n",
    "        results_loss[3].append(test_acc_loss[j][2])\n",
    "        results_loss[4].append(all_without_train_acc_loss[j][2])\n",
    "        results_loss[5].append(np.abs(all_without_train_acc_loss[j][2]-test_acc_loss[j][2]))\n",
    "    \n",
    "    results_acc = np.round(results_acc,1)\n",
    "    results_loss = np.round(results_loss,1)\n",
    "    \n",
    "    results_acc = np.array(results_acc)\n",
    "    results_loss = np.array(results_loss)\n",
    "    \n",
    "    d = pd.DataFrame({\n",
    "        'index':np.array(results_acc[0],dtype=np.int32),\n",
    "        'images':np.array(results_acc[1],dtype=np.int32),\n",
    "        'train':results_acc[2],\n",
    "        'test':results_acc[3],\n",
    "        'all':results_acc[4],\n",
    "        'all-test':results_acc[5]\n",
    "    })\n",
    "    d.to_csv('./Clapeyron_CNN_research/tableAccClapeyron_CNN_v0.2.csv',index=False,\n",
    "             columns=['index','images','train','test','all','all-test'])\n",
    "    \n",
    "    d = pd.DataFrame({\n",
    "        'index':np.array(results_loss[0],dtype=np.int32),\n",
    "        'images':np.array(results_loss[1],dtype=np.int32),\n",
    "        'train':results_loss[2],\n",
    "        'test':results_loss[3],\n",
    "        'all':results_loss[4],\n",
    "        'all-test':results_loss[5]\n",
    "    })\n",
    "    d.to_csv('./Clapeyron_CNN_research/tableLossClapeyron_CNN_v0.2.csv',index=False,\n",
    "                columns=['index','images','train','test','all','all-test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./modelTmp/model_v0.2_iter14000.ckpt\n",
      "test_acc_loss_mean (34.5, 5.6506006717681885)\n"
     ]
    }
   ],
   "source": [
    "results('./modelTmp/model_v0.2_iter14000.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
